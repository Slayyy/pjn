{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "from collections import Counter\n",
    "from math import *\n",
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def case(c):\n",
    "    with open(f\"{c}/train.pkl\", \"rb\") as f:\n",
    "        X_train = pickle.load(f)\n",
    "    with open(f\"{c}/test.pkl\", \"rb\") as f:\n",
    "        X_test = pickle.load(f)\n",
    "\n",
    "    train_groups = json.load(open(f\"{c}/train_groups.json\"))\n",
    "    test_groups = json.load(open(f\"{c}/test_groups.json\"))\n",
    "    \n",
    "    print(f\"----{c}----\\n\")\n",
    "    print(f\"X_train.shape {X_train.shape}\")\n",
    "    print(f\"X_test.shape {X_test.shape}\")\n",
    "    \n",
    "    for group in sorted(list(set(train_groups))):\n",
    "        print(f\"{group}\")\n",
    "        Y_train = np.asarray([1 if train_group == group else 0 \n",
    "                                    for train_group in train_groups])\n",
    "        Y_test = np.asarray([1 if test_group == group else 0 \n",
    "                                    for test_group in test_groups])\n",
    "#         tuned_parameters = [\n",
    "#              {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "#                       'C': [1, 10, 100, 1000]},\n",
    "#                      {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "#         clf = GridSearchCV(SVC(), tuned_parameters, cv=5,\n",
    "#                        scoring='f1')\n",
    "#         clf.fit(train_data, train_classes)\n",
    "#         print(clf.best_params_)\n",
    "\n",
    "        clf = SVC(kernel=\"linear\", C=100)\n",
    "        clf.fit(X_train, Y_train)\n",
    "        \n",
    "        Y_res = clf.predict(X_test)\n",
    "        print(classification_report(Y_test, Y_res))\n",
    "        \n",
    "        print(\"\\tf1 macro\", f1_score(Y_test, Y_res, average='macro'))  \n",
    "        print(\"\\tf1 micro\", f1_score(Y_test, Y_res, average='micro'))  \n",
    "\n",
    "        print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----normal----\n",
      "X_train.shape (27518, 83907)\n",
      "X_test.shape (9176, 83907)\n",
      "A?C.*\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.95      0.97      4648\n",
      "          1       0.95      0.99      0.97      4528\n",
      "\n",
      "avg / total       0.97      0.97      0.97      9176\n",
      "\n",
      "\tf1 macro 0.9697028131452883\n",
      "\tf1 micro 0.9697035745422842\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A?K.*\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      7309\n",
      "          1       0.99      0.99      0.99      1867\n",
      "\n",
      "avg / total       1.00      1.00      1.00      9176\n",
      "\n",
      "\tf1 macro 0.9947875795175125\n",
      "\tf1 micro 0.9966216216216216\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A?P.*\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      8698\n",
      "          1       0.97      0.91      0.94       478\n",
      "\n",
      "avg / total       0.99      0.99      0.99      9176\n",
      "\n",
      "\tf1 macro 0.9693555856369336\n",
      "\tf1 micro 0.9941150828247602\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A?U.*\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      7489\n",
      "          1       1.00      1.00      1.00      1687\n",
      "\n",
      "avg / total       1.00      1.00      1.00      9176\n",
      "\n",
      "\tf1 macro 0.9992740359298418\n",
      "\tf1 micro 0.9995640802092415\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Am.*\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      9152\n",
      "          1       0.83      0.42      0.56        24\n",
      "\n",
      "avg / total       1.00      1.00      1.00      9176\n",
      "\n",
      "\tf1 macro 0.777341001189003\n",
      "\tf1 micro 0.998256320836966\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "G.*\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      8798\n",
      "          1       0.89      0.57      0.69       378\n",
      "\n",
      "avg / total       0.98      0.98      0.98      9176\n",
      "\n",
      "\tf1 macro 0.8403334618780263\n",
      "\tf1 micro 0.9791848299912816\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "R.*\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      9172\n",
      "          1       1.00      0.50      0.67         4\n",
      "\n",
      "avg / total       1.00      1.00      1.00      9176\n",
      "\n",
      "\tf1 macro 0.8332788255387187\n",
      "\tf1 micro 0.9997820401046208\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "W.*\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      8966\n",
      "          1       0.97      0.93      0.95       210\n",
      "\n",
      "avg / total       1.00      1.00      1.00      9176\n",
      "\n",
      "\tf1 macro 0.9751707417389139\n",
      "\tf1 micro 0.9978204010462075\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "case(\"normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----lemmatised----\n",
      "X_train.shape (27518, 26780)\n",
      "X_test.shape (9176, 26780)\n",
      "A?C.*\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.95      0.97      4648\n",
      "          1       0.95      0.99      0.97      4528\n",
      "\n",
      "avg / total       0.97      0.97      0.97      9176\n",
      "\n",
      "\tf1 macro 0.9694838387441891\n",
      "\tf1 micro 0.969485614646905\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A?K.*\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      7309\n",
      "          1       0.99      0.99      0.99      1867\n",
      "\n",
      "avg / total       1.00      1.00      1.00      9176\n",
      "\n",
      "\tf1 macro 0.9932594908697174\n",
      "\tf1 micro 0.995640802092415\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A?P.*\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      8698\n",
      "          1       0.98      0.90      0.94       478\n",
      "\n",
      "avg / total       0.99      0.99      0.99      9176\n",
      "\n",
      "\tf1 macro 0.966207698218711\n",
      "\tf1 micro 0.9935701830863121\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A?U.*\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      7489\n",
      "          1       1.00      1.00      1.00      1687\n",
      "\n",
      "avg / total       1.00      1.00      1.00      9176\n",
      "\n",
      "\tf1 macro 0.9985474051925041\n",
      "\tf1 micro 0.999128160418483\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Am.*\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      9152\n",
      "          1       0.81      0.54      0.65        24\n",
      "\n",
      "avg / total       1.00      1.00      1.00      9176\n",
      "\n",
      "\tf1 macro 0.8246177370030581\n",
      "\tf1 micro 0.9984742807323452\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "G.*\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      8798\n",
      "          1       0.95      0.44      0.61       378\n",
      "\n",
      "avg / total       0.98      0.98      0.97      9176\n",
      "\n",
      "\tf1 macro 0.7971248138455502\n",
      "\tf1 micro 0.9762423714036618\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "R.*\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      9172\n",
      "          1       1.00      0.25      0.40         4\n",
      "\n",
      "avg / total       1.00      1.00      1.00      9176\n",
      "\n",
      "\tf1 macro 0.6999182427644847\n",
      "\tf1 micro 0.9996730601569311\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "W.*\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      8966\n",
      "          1       0.96      0.91      0.94       210\n",
      "\n",
      "avg / total       1.00      1.00      1.00      9176\n",
      "\n",
      "\tf1 macro 0.9687410023073609\n",
      "\tf1 micro 0.9972755013077593\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "case(\"lemmatised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
